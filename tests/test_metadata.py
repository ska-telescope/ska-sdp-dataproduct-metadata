"""Test Generating Metadata File."""

import json
import logging
import os

import pytest
import ska_sdp_config
import yaml

from ska_sdp_dataproduct_metadata import MetaData, new_config_client

LOG = logging.getLogger("metadata-test")
LOG.setLevel(logging.DEBUG)

CONFIG_DB_CLIENT = new_config_client()
SUBARRAY_ID = "01"
PATH_LIST = [
    {"path": "vis.ms", "description": "raw visibilities"},
    {"path": "vis_new.ms", "description": "extra visibilities"},
]
INPUT_FILE = "tests/resources/test_metadata_default.yaml"
OUTPUT_PATH = "tests/resources/temp_output_metadata.yaml"
OUTPUT_METADATA = "tests/resources/expected_metadata.yaml"
OUTPUT_METADATA_WITHOUT_FILES = (
    "tests/resources/expected_metadata_without_files.yaml"
)
OUTPUT_METADATA_WITH_FILES = (
    "tests/resources/expected_metadata_with_files.yaml"
)
UPDATED_METADATA = "tests/resources/expected_updated_metadata.yaml"


def test_create():
    """
    Test the creation of the Metadata file using
    default parameters
    """

    create_eb_pb()

    MetaData()

    assert 1 == 2
    # MetaData(
    #     input_file=INPUT_FILE,
    #     eb_id="eb-test-20220916-00000",
    #     pb_id="pb-test-20220916-00000",
    #     processing_script="vis-receive",
    #     output_path=OUTPUT_PATH,
    # )
    # metadata = read_file(OUTPUT_PATH)
    # expected_metadata = read_file(OUTPUT_METADATA_WITHOUT_FILES)
    # assert metadata == expected_metadata
    #
    # # Clean up
    # delete_file(OUTPUT_PATH)


# def test_update_status():
#     """Test updating the status of the files"""
#     metadata = MetaData(
#         input_file=INPUT_FILE,
#         eb_id="eb-test-20220916-00000",
#         pb_id="pb-test-20220916-00000",
#         processing_script="vis-receive",
#         output_path=OUTPUT_PATH,
#     )
#     metadata.add_path_to_files(PATH_LIST)
#     metadata_with_files = read_file(OUTPUT_PATH)
#     expected_metadata = read_file(OUTPUT_METADATA_WITH_FILES)
#     assert metadata_with_files == expected_metadata
#
#     metadata.update_file_status("vis.ms", "done")
#     updated_file = read_file(OUTPUT_PATH)
#     expected_update_metadata = read_file(UPDATED_METADATA)
#     assert updated_file == expected_update_metadata
#
#     # Clean up
#     delete_file(OUTPUT_PATH)
#
#
# def read_file(file):
#     """Read and load files into yaml"""
#     with open(file, "r", encoding="utf8") as input_file:
#         data = yaml.safe_load(input_file)
#     return data
#
#
# def delete_file(file):
#     """Delete output files generated by the tests"""
#
#     LOG.info("I am inside this function")
#
#     if os.path.exists(file):
#         os.remove(file)
#     else:
#         LOG.info("The file does not exist")
#
#
# def test_create_no_eb_id():
#     """
#     Check that ValueError is raised when there is no execution block ID"
#     """
#
#     with pytest.raises(ValueError, match=r"Execution Block ID is None!"):
#         MetaData(
#             input_file=INPUT_FILE,
#             pb_id="pb-test-20220916-00000",
#             processing_script="vis-receive",
#             output_path=OUTPUT_PATH,
#         )
#
#
# def test_create_no_pb_id():
#     """
#     Check that ValueError is raised when there is no processing block ID"
#     """
#
#     with pytest.raises(ValueError, match=r"Processing Block ID is None!"):
#         MetaData(
#             input_file=INPUT_FILE,
#             eb_id="eb-test-20220916-00000",
#             processing_script="vis-receive",
#             output_path=OUTPUT_PATH,
#         )
#
#
# def test_create_no_processing_script():
#     """
#     Check that ValueError is raised when there is no processing script"
#     """
#
#     with pytest.raises(ValueError, match=r"Processing Script is None!"):
#         MetaData(
#             input_file=INPUT_FILE,
#             eb_id="eb-test-20220916-00000",
#             pb_id="pb-test-20220916-00000",
#             output_path=OUTPUT_PATH,
#         )


def create_eb_pb():
    """Create execution block and processing block."""
    eb, pbs = get_eb_pbs()
    for txn in CONFIG_DB_CLIENT.txn():
        eb_id = eb.get("eb_id")
        if eb_id is not None:
            txn.create_execution_block(eb_id, eb)
        for pb in pbs:
            txn.create_processing_block(pb)


def read_configuration_string():
    """Read configuration string from JSON file."""
    return read_json_data("configuration_string.json", decode=True)


def get_eb_pbs():
    """Get EB and PBs from configuration string."""
    config = read_configuration_string()

    pbs_from_config = config.pop("processing_blocks")
    eb_id = config.get("eb_id")

    eb_config = config.copy()
    eb_extra = {
        "subarray_id": SUBARRAY_ID,
        "pb_realtime": [],
        "pb_batch": [],
        "pb_receive_addresses": None,
        "current_scan_type": None,
        "scan_id": None,
        "status": "ACTIVE",
    }
    eb = {**eb_extra, **eb_config}

    pbs = []
    for pbc in pbs_from_config:
        pb_id = pbc.get("pb_id")
        kind = pbc.get("script").get("kind")
        eb["pb_" + kind].append(pb_id)
        if "dependencies" in pbc:
            dependencies = pbc.get("dependencies")
        else:
            dependencies = []
        pb = ska_sdp_config.ProcessingBlock(
            pb_id,
            eb_id,
            pbc.get("script"),
            parameters=pbc.get("parameters"),
            dependencies=dependencies,
        )
        pbs.append(pb)

    return eb, pbs


def read_json_data(filename, decode=False):
    """Read JSON file from data directory.

    :param decode: decode the JSON dat into Python

    """
    path = os.path.join(os.path.dirname(__file__), "resources", filename)
    with open(path, "r", encoding="utf8") as file:
        data = file.read()
    if decode:
        data = json.loads(data)
    return data
